{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch_geometric import nn\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test_edges = pd.read_parquet('../data/graphs/test_edges.parquet')\n",
    "test_features = pd.read_parquet('../data/graphs/test_features.parquet')\n",
    "test_labels = pd.read_parquet('../data/graphs/test_labels_neg.parquet')\n",
    "\n",
    "val_edges = pd.read_parquet('../data/graphs/val_edges.parquet')\n",
    "val_features = pd.read_parquet('../data/graphs/val_features.parquet')\n",
    "val_labels = pd.read_parquet('../data/graphs/val_labels_neg.parquet')\n",
    "\n",
    "train_edges = pd.read_parquet('../data/graphs/train_edges.parquet')\n",
    "train_features = pd.read_parquet('../data/graphs/train_features.parquet')\n",
    "train_labels = pd.read_parquet('../data/graphs/train_labels_neg.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_features = np.load('../data/feature_emb/products.npy')\n",
    "user_features = np.load('../data/feature_agg/train_user_features_norm.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101696, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc_user_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enc_user_id  user_id\n",
       "0            0        1\n",
       "1            1        2\n",
       "2            2        3\n",
       "3            3        7\n",
       "4            4       13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_user_id = train_edges[[\"user_id\"]].drop_duplicates().sort_values(\"user_id\").reset_index(drop=True).reset_index().rename(columns={\"index\": \"enc_user_id\"})\n",
    "print(enc_user_id.shape)\n",
    "enc_user_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_user_id_dict = dict(zip(enc_user_id.user_id, enc_user_id.enc_user_id))\n",
    "enc_user_id_dict[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode user_id\n",
    "train_edges[\"enc_user_id\"] = train_edges[\"user_id\"].map(enc_user_id_dict)\n",
    "val_edges[\"enc_user_id\"] = val_edges[\"user_id\"].map(enc_user_id_dict)\n",
    "test_edges[\"enc_user_id\"] = test_edges[\"user_id\"].map(enc_user_id_dict)\n",
    "train_labels[\"enc_user_id\"] = train_labels[\"user_id\"].map(enc_user_id_dict)\n",
    "val_labels[\"enc_user_id\"] = val_labels[\"user_id\"].map(enc_user_id_dict)\n",
    "test_labels[\"enc_user_id\"] = test_labels[\"user_id\"].map(enc_user_id_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>enc_user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675716</th>\n",
       "      <td>206209</td>\n",
       "      <td>41665</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675717</th>\n",
       "      <td>206209</td>\n",
       "      <td>43961</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675718</th>\n",
       "      <td>206209</td>\n",
       "      <td>44325</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675719</th>\n",
       "      <td>206209</td>\n",
       "      <td>48697</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8675720</th>\n",
       "      <td>206209</td>\n",
       "      <td>48742</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>101695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675721 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  product_id    weight  enc_user_id\n",
       "0              1         196  0.700000            0\n",
       "1              1       10258  0.600000            0\n",
       "2              1       10326  0.100000            0\n",
       "3              1       12427  0.700000            0\n",
       "4              1       13032  0.200000            0\n",
       "...          ...         ...       ...          ...\n",
       "8675716   206209       41665  0.076923       101695\n",
       "8675717   206209       43961  0.153846       101695\n",
       "8675718   206209       44325  0.076923       101695\n",
       "8675719   206209       48697  0.076923       101695\n",
       "8675720   206209       48742  0.076923       101695\n",
       "\n",
       "[8675721 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_index = torch.tensor(train_edges[[\"enc_user_id\", \"product_id\"]].values, dtype=torch.long).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = HeteroData()\n",
    "\n",
    "# Save node indices:\n",
    "train_data[\"user\"].node_id = torch.arange(user_features.shape[0])\n",
    "train_data[\"prod\"].node_id = torch.arange(prod_features.shape[0])\n",
    "\n",
    "\n",
    "# Add the node features and edge indices:\n",
    "train_data[\"user\"].x = user_features\n",
    "train_data[\"prod\"].x = prod_features\n",
    "train_data[\"user\", \"buy\", \"prod\"].edge_index = edge_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1muser\u001b[0m={\n",
      "    node_id=[101696],\n",
      "    x=[101696, 22]\n",
      "  },\n",
      "  \u001b[1mprod\u001b[0m={\n",
      "    node_id=[49689],\n",
      "    x=[49689, 768]\n",
      "  },\n",
      "  \u001b[1m(user, buy, prod)\u001b[0m={ edge_index=[2, 8675721] },\n",
      "  \u001b[1m(prod, rev_buy, user)\u001b[0m={ edge_index=[2, 8675721] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "train_data = T.ToUndirected()(train_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1muser\u001b[0m={\n",
       "    node_id=[101696],\n",
       "    x=[101696, 22]\n",
       "  },\n",
       "  \u001b[1mprod\u001b[0m={\n",
       "    node_id=[49689],\n",
       "    x=[49689, 768]\n",
       "  },\n",
       "  \u001b[1m(user, buy, prod)\u001b[0m={\n",
       "    edge_index=[2, 8675721],\n",
       "    edge_label_index=[2, 661052],\n",
       "    edge_label=[661052]\n",
       "  },\n",
       "  \u001b[1m(prod, rev_buy, user)\u001b[0m={ edge_index=[2, 8675721] }\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"user\", \"buy\", \"prod\"].edge_label_index = torch.tensor(train_labels[[\"enc_user_id\", \"product_id\"]].values, dtype=torch.long).t().contiguous()\n",
    "train_data[\"user\", \"buy\", \"prod\"].edge_label = torch.tensor(train_labels[\"label\"].values, dtype=torch.long).t().contiguous()\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 23\u001b[0m\n\u001b[1;32m     12\u001b[0m train_loader \u001b[39m=\u001b[39m LinkNeighborLoader(\n\u001b[1;32m     13\u001b[0m     data\u001b[39m=\u001b[39mtrain_data,\n\u001b[1;32m     14\u001b[0m     num_neighbors\u001b[39m=\u001b[39m[\u001b[39m20\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m10\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[39m# Inspect a sample:\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m sampled_data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_loader))\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSampled mini-batch:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m===================\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/torch_geometric/loader/base.py:36\u001b[0m, in \u001b[0;36mDataLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_fn(\u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterator))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/torch_geometric/loader/link_loader.py:182\u001b[0m, in \u001b[0;36mLinkLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[1;32m    180\u001b[0m input_data: EdgeSamplerInput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_data[index]\n\u001b[0;32m--> 182\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlink_sampler\u001b[39m.\u001b[39;49msample_from_edges(\n\u001b[1;32m    183\u001b[0m     input_data, neg_sampling\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneg_sampling)\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_per_worker:  \u001b[39m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/torch_geometric/sampler/neighbor_sampler.py:182\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_edges\u001b[0;34m(self, inputs, neg_sampling)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msample_from_edges\u001b[39m(\n\u001b[1;32m    179\u001b[0m     \u001b[39mself\u001b[39m, inputs: EdgeSamplerInput,\n\u001b[1;32m    180\u001b[0m     neg_sampling: Optional[NegativeSampling] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    181\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mreturn\u001b[39;00m edge_sample(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sample, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_nodes, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdisjoint,\n\u001b[1;32m    183\u001b[0m                        \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_time, neg_sampling)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/torch_geometric/sampler/neighbor_sampler.py:481\u001b[0m, in \u001b[0;36medge_sample\u001b[0;34m(inputs, sample_fn, num_nodes, disjoint, node_time, neg_sampling)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[39mif\u001b[39;00m edge_label_time \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Always disjoint.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m         seed_time_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m    478\u001b[0m             input_type[\u001b[39m0\u001b[39m]: torch\u001b[39m.\u001b[39mcat([src_time, dst_time], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m),\n\u001b[1;32m    479\u001b[0m         }\n\u001b[0;32m--> 481\u001b[0m out \u001b[39m=\u001b[39m sample_fn(seed_dict, seed_time_dict)\n\u001b[1;32m    483\u001b[0m \u001b[39m# Enhance `out` by label information ##################################\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m disjoint:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/graph/lib/python3.9/site-packages/torch_geometric/sampler/neighbor_sampler.py:259\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     num_sampled_nodes \u001b[39m=\u001b[39m num_sampled_edges \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m requires \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m                       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meither \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyg-lib\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtorch-sparse\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m num_sampled_edges \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     num_sampled_edges \u001b[39m=\u001b[39m remap_keys(\n\u001b[1;32m    264\u001b[0m         num_sampled_edges,\n\u001b[1;32m    265\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_edge_type,\n\u001b[1;32m    266\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: 'NeighborSampler' requires either 'pyg-lib' or 'torch-sparse'"
     ]
    }
   ],
   "source": [
    "# In the first hop, we sample at most 20 neighbors.\n",
    "# In the second hop, we sample at most 10 neighbors.\n",
    "# In addition, during training, we want to sample negative edges on-the-fly with\n",
    "# a ratio of 2:1.\n",
    "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "\n",
    "# Define seed edges:\n",
    "edge_label_index = train_data[\"user\", \"buy\", \"prod\"].edge_label_index\n",
    "edge_label = train_data[\"user\", \"buy\", \"prod\"].edge_label\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[20, 10, 10],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    edge_label_index=((\"user\", \"buy\", \"prod\"), edge_label_index),\n",
    "    edge_label=edge_label,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Inspect a sample:\n",
    "sampled_data = next(iter(train_loader))\n",
    "\n",
    "print(\"Sampled mini-batch:\")\n",
    "print(\"===================\")\n",
    "print(sampled_data)\n",
    "\n",
    "assert sampled_data[\"user\", \"buy\", \"prod\"].edge_label_index.size(1) == 3 * 128\n",
    "assert sampled_data[\"user\", \"buy\", \"prod\"].edge_label.min() == 0\n",
    "assert sampled_data[\"user\", \"buy\", \"prod\"].edge_label.max() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
