{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "import pickle\n",
    "from copy import deepcopy\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDExplicitBiasMF:\n",
    "    def __init__(self, \n",
    "                 ratings,\n",
    "                 ratings_eval,\n",
    "                 n_factors=64,\n",
    "                 early_stopping_rounds=10,\n",
    "                 item_fact_reg=0.0, \n",
    "                 user_fact_reg=0.0,\n",
    "                 item_bias_reg=0.0,\n",
    "                 user_bias_reg=0.0,\n",
    "                 verbose=False,\n",
    "                 model_saving_path=\".\"):\n",
    "        \"\"\"\n",
    "        Link: [ExplicitMF](https://www.ethanrosenthal.com/2016/01/09/explicit-matrix-factorization-sgd-als/)\n",
    "        Train a matrix factorization model to predict empty \n",
    "        entries in a matrix. The terminology assumes a \n",
    "        ratings matrix which is ~ user x item\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "        ratings : (ndarray)\n",
    "            User x Item matrix with corresponding ratings\n",
    "        \n",
    "        n_factors : (int)\n",
    "            Number of latent factors to use in matrix \n",
    "            factorization model\n",
    "        \n",
    "        item_fact_reg : (float)\n",
    "            Regularization term for item latent factors\n",
    "        \n",
    "        user_fact_reg : (float)\n",
    "            Regularization term for user latent factors\n",
    "            \n",
    "        item_bias_reg : (float)\n",
    "            Regularization term for item biases\n",
    "        \n",
    "        user_bias_reg : (float)\n",
    "            Regularization term for user biases\n",
    "        \n",
    "        verbose : (bool)\n",
    "            Whether or not to printout training progress\n",
    "        \"\"\"\n",
    "        \n",
    "        self.ratings = ratings\n",
    "        self.n_users, self.n_items = ratings.shape\n",
    "        self.ratings_eval = ratings_eval\n",
    "        self.n_factors = n_factors\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.item_fact_reg = item_fact_reg\n",
    "        self.user_fact_reg = user_fact_reg\n",
    "        self.item_bias_reg = item_bias_reg\n",
    "        self.user_bias_reg = user_bias_reg\n",
    "        self.sample_row, self.sample_col = self.ratings.nonzero()\n",
    "        self.n_samples = len(self.sample_row)\n",
    "        self._v = verbose\n",
    "        self._manual_init_bias = False\n",
    "        self.model_saving_path = model_saving_path\n",
    "\n",
    "    def init_bias(self, user_bias_init, item_bias_init):\n",
    "        self.global_bias = np.mean(self.ratings[self.ratings != 0])\n",
    "        self.user_bias = user_bias_init\n",
    "        self.item_bias = item_bias_init\n",
    "        self._manual_init_bias = True\n",
    "\n",
    "    def train(self, max_iter=200, learning_rate=0.005, pretrained=False):\n",
    "        \"\"\" Train model for n_iter iterations from scratch.\"\"\"\n",
    "        # initialize latent vectors\n",
    "        if not pretrained:\n",
    "            self.user_vecs = np.random.normal(scale=1./self.n_factors,\\\n",
    "                                            size=(self.n_users, self.n_factors))\n",
    "            self.item_vecs = np.random.normal(scale=1./self.n_factors,\n",
    "                                            size=(self.n_items, self.n_factors))\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        if (not self._manual_init_bias) and (not pretrained):\n",
    "            self.user_bias = np.zeros(self.n_users)\n",
    "            self.item_bias = np.zeros(self.n_items)\n",
    "            self.global_bias = np.mean(self.ratings[self.ratings != 0])\n",
    "\n",
    "        self.min_mse_eval = np.Inf\n",
    "        self.list_mse_eval = []\n",
    "\n",
    "        self.partial_train(n_iter=max_iter, save_interim = True)\n",
    "    \n",
    "    \n",
    "    def partial_train(self, n_iter, save_interim = True):\n",
    "        \"\"\" \n",
    "        Train model for n_iter iterations. Can be \n",
    "        called multiple times for further training.\n",
    "        \"\"\"\n",
    "        iter_cnt = 1\n",
    "        while iter_cnt <= n_iter:\n",
    "            \n",
    "            self.training_indices = np.arange(self.n_samples)\n",
    "            np.random.shuffle(self.training_indices)\n",
    "            self.iter_idx = iter_cnt\n",
    "            self.sgd()\n",
    "            # Save interim model\n",
    "            if save_interim:\n",
    "                now = int(time.time())\n",
    "                to_save = deepcopy(self)\n",
    "                to_save.ratings = np.zeros((2,2))\n",
    "                to_save.ratings_eval = np.zeros((2,2))\n",
    "                with open(f\"{self.model_saving_path}/model_sgd_mf_v4_{self.iter_idx}__{now}.pkl\", \"wb\") as f:\n",
    "                    pickle.dump(to_save, file=f)\n",
    "            # evaluate the model\n",
    "            eval_mse = self.evaluate(self.ratings_eval)\n",
    "            self.min_mse_eval = min(eval_mse, self.min_mse_eval)\n",
    "            self.list_mse_eval.append(eval_mse)\n",
    "            if self._v:\n",
    "                print(f\"Iteration {iter_cnt}. Latest MSE: {eval_mse:.4f}. Min MSE: {self.min_mse_eval:.4f}.\")\n",
    "            \n",
    "\n",
    "            if min(self.list_mse_eval[-self.early_stopping_rounds:]) > self.min_mse_eval: \n",
    "                print(\"Early stopping due to non-improvement on the test set\")\n",
    "                break\n",
    "            iter_cnt += 1\n",
    "\n",
    "    def load_model(self, pickled_file, rating_train, rating_eval):\n",
    "        with open(pickled_file, \"rb\") as f:\n",
    "            self = pickle.load(file=f)\n",
    "            self.ratings = rating_train\n",
    "            self.ratings_eval = rating_eval\n",
    "\n",
    "    def sgd(self):\n",
    "        for idx in self.training_indices:\n",
    "            u = self.sample_row[idx]\n",
    "            i = self.sample_col[idx]\n",
    "            prediction = self.predict(u, i)\n",
    "            e = (self.ratings[u,i] - prediction) # error\n",
    "            \n",
    "            # Update biases\n",
    "            self.user_bias[u] += self.learning_rate * \\\n",
    "                                (e - self.user_bias_reg * self.user_bias[u])\n",
    "            self.item_bias[i] += self.learning_rate * \\\n",
    "                                (e - self.item_bias_reg * self.item_bias[i])\n",
    "            \n",
    "            #Update latent factors\n",
    "            self.user_vecs[u, :] += self.learning_rate * \\\n",
    "                                    (e * self.item_vecs[i, :] - \\\n",
    "                                     self.user_fact_reg * self.user_vecs[u,:])\n",
    "            self.item_vecs[i, :] += self.learning_rate * \\\n",
    "                                    (e * self.user_vecs[u, :] - \\\n",
    "                                     self.item_fact_reg * self.item_vecs[i,:])\n",
    "            # if idx % 1000 == 0:\n",
    "            #     print(idx)\n",
    "            \n",
    "    def predict(self, u, i):\n",
    "        \"\"\" Single user and item prediction.\"\"\"\n",
    "        prediction = self.global_bias + self.user_bias[u] + self.item_bias[i]\n",
    "        prediction += self.user_vecs[u, :].dot(self.item_vecs[i, :].T)\n",
    "        return prediction\n",
    "    \n",
    "    def predict_all(self):\n",
    "        \"\"\" Predict ratings for every user and item.\"\"\"\n",
    "        predictions = np.zeros((self.user_vecs.shape[0], \n",
    "                                self.item_vecs.shape[0]), dtype='uint8')\n",
    "        for u in range(self.user_vecs.shape[0]):\n",
    "            for i in range(self.item_vecs.shape[0]):\n",
    "                predictions[u, i] = self.predict(u, i)\n",
    "        return predictions\n",
    "\n",
    "    def evaluate(self, test_sparse_matrix):\n",
    "        nz_row, nz_col = test_sparse_matrix.nonzero()\n",
    "        n_idx = len(nz_row)\n",
    "        rating_pred = np.zeros(n_idx)\n",
    "        rating_true = np.zeros(n_idx)\n",
    "        for idx in np.arange(n_idx):\n",
    "            irow, icol = nz_row[idx], nz_col[idx]\n",
    "            rating_pred[idx] = self.predict(irow, icol)\n",
    "            rating_true[idx] = test_sparse_matrix[irow, icol]\n",
    "        mse = mean_squared_error(rating_true, rating_pred)\n",
    "        return mse\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_parquet('graphs/train_labels_neg.parquet')\n",
    "\n",
    "val_labels = pd.read_parquet('graphs/val_labels_neg.parquet')\n",
    "\n",
    "test_labels = pd.read_parquet('graphs/test_labels_neg.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>46149</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>49235</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32022</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>44593</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>47186</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661047</th>\n",
       "      <td>206206</td>\n",
       "      <td>12902</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661048</th>\n",
       "      <td>206209</td>\n",
       "      <td>48370</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661049</th>\n",
       "      <td>206209</td>\n",
       "      <td>40310</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661050</th>\n",
       "      <td>206209</td>\n",
       "      <td>27857</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661051</th>\n",
       "      <td>206209</td>\n",
       "      <td>46898</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>661052 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  product_id  label\n",
       "0             1       46149   1.01\n",
       "1             1       49235   1.01\n",
       "2             1       32022   0.01\n",
       "3             1       44593   0.01\n",
       "4             2       47186   0.01\n",
       "...         ...         ...    ...\n",
       "661047   206206       12902   0.01\n",
       "661048   206209       48370   1.01\n",
       "661049   206209       40310   1.01\n",
       "661050   206209       27857   0.01\n",
       "661051   206209       46898   0.01\n",
       "\n",
       "[661052 rows x 3 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_edges= pd.read_parquet('graphs/train_edges.parquet')\n",
    "#val_labels=pd.read_parquet('graphs/val_edges.parquet')\n",
    "#test_labels=pd.read_parquet('graphs/test_edges.parquet')\n",
    "train_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels=train_labels.rename(columns={\"weight\": \"label\"})\n",
    "#val_labels=val_labels.rename(columns={\"weight\": \"label\"})\n",
    "#test_labels=test_labels.rename(columns={\"weight\": \"label\"})\n",
    "#train_labels.product_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels['label'] = train_labels['label']+0.01\n",
    "val_labels['label'] = val_labels['label']+0.01\n",
    "test_labels['label'] = test_labels['label']+0.01\n",
    "train_set = csr_matrix((train_labels.label, (train_labels.user_id, train_labels.product_id)), shape=(206209+1, 49688+1))\n",
    "eval_set = csr_matrix((val_labels.label, (val_labels.user_id, val_labels.product_id)), shape=(206209+1, 49688+1))\n",
    "test_set = csr_matrix((test_labels.label, (test_labels.user_id, test_labels.product_id)), shape=(206209+1, 49688+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49688"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_edges=train_edges.drop(labels='weight', axis=1)\n",
    "#val_edges=val_edges.drop(labels='weight', axis=1)\n",
    "#train_edges['label']=1\n",
    "##val_edges['label']=1\n",
    "#test_edges=test_edges.drop(labels='weight', axis=1)\n",
    "#test_edges['label']=1\n",
    "\n",
    "#train_labels=train_edges\n",
    "#val_labels=val_edges\n",
    "#test_labels=test_edges\n",
    "\n",
    "#train_labels.product_id.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1. Latest MSE: 0.1861. Min MSE: 0.1861.\n",
      "Iteration 2. Latest MSE: 0.1705. Min MSE: 0.1705.\n",
      "Iteration 3. Latest MSE: 0.1609. Min MSE: 0.1609.\n",
      "Iteration 4. Latest MSE: 0.1541. Min MSE: 0.1541.\n",
      "Iteration 5. Latest MSE: 0.1492. Min MSE: 0.1492.\n",
      "Iteration 6. Latest MSE: 0.1454. Min MSE: 0.1454.\n",
      "Iteration 7. Latest MSE: 0.1424. Min MSE: 0.1424.\n",
      "Iteration 8. Latest MSE: 0.1402. Min MSE: 0.1402.\n",
      "Iteration 9. Latest MSE: 0.1384. Min MSE: 0.1384.\n",
      "Iteration 10. Latest MSE: 0.1371. Min MSE: 0.1371.\n",
      "Iteration 11. Latest MSE: 0.1360. Min MSE: 0.1360.\n",
      "Iteration 12. Latest MSE: 0.1352. Min MSE: 0.1352.\n",
      "Iteration 13. Latest MSE: 0.1346. Min MSE: 0.1346.\n",
      "Iteration 14. Latest MSE: 0.1341. Min MSE: 0.1341.\n",
      "Iteration 15. Latest MSE: 0.1337. Min MSE: 0.1337.\n",
      "Iteration 16. Latest MSE: 0.1335. Min MSE: 0.1335.\n",
      "Iteration 17. Latest MSE: 0.1333. Min MSE: 0.1333.\n",
      "Iteration 18. Latest MSE: 0.1332. Min MSE: 0.1332.\n",
      "Iteration 19. Latest MSE: 0.1331. Min MSE: 0.1331.\n",
      "Iteration 20. Latest MSE: 0.1331. Min MSE: 0.1331.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sgd_mf_model = SGDExplicitBiasMF(ratings=train_set, \n",
    "    ratings_eval = eval_set, n_factors = 128, \n",
    "    early_stopping_rounds=10, verbose=True,\n",
    "    \n",
    "    item_fact_reg=0.00, item_bias_reg=0.00,\n",
    "    user_fact_reg=0.00, user_bias_reg=0.00)\n",
    "sgd_mf_model.train(max_iter=20, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206060</th>\n",
       "      <td>64409</td>\n",
       "      <td>24184</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.310922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528248</th>\n",
       "      <td>165539</td>\n",
       "      <td>10246</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.298103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101955</th>\n",
       "      <td>32099</td>\n",
       "      <td>24852</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.294436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438214</th>\n",
       "      <td>137389</td>\n",
       "      <td>42265</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.294124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342604</th>\n",
       "      <td>106876</td>\n",
       "      <td>5450</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.283134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424429</th>\n",
       "      <td>133102</td>\n",
       "      <td>24964</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.275113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649670</th>\n",
       "      <td>204080</td>\n",
       "      <td>43961</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.274052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94622</th>\n",
       "      <td>29982</td>\n",
       "      <td>260</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.272359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508168</th>\n",
       "      <td>159326</td>\n",
       "      <td>4920</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.271624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231034</th>\n",
       "      <td>72344</td>\n",
       "      <td>40377</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.271510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58671</th>\n",
       "      <td>18390</td>\n",
       "      <td>34126</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.271082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58670</th>\n",
       "      <td>18390</td>\n",
       "      <td>31717</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.270711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556533</th>\n",
       "      <td>174219</td>\n",
       "      <td>8670</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.266990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379310</th>\n",
       "      <td>118457</td>\n",
       "      <td>34969</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.265934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58676</th>\n",
       "      <td>18390</td>\n",
       "      <td>47626</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.265028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394044</th>\n",
       "      <td>123133</td>\n",
       "      <td>26209</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.264964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75196</th>\n",
       "      <td>23586</td>\n",
       "      <td>25659</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.264722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341262</th>\n",
       "      <td>106464</td>\n",
       "      <td>22935</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.263821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58675</th>\n",
       "      <td>18390</td>\n",
       "      <td>22935</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.262720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82702</th>\n",
       "      <td>25992</td>\n",
       "      <td>34126</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.262075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  product_id  label      pred\n",
       "206060    64409       24184   1.01  1.310922\n",
       "528248   165539       10246   1.01  1.298103\n",
       "101955    32099       24852   1.01  1.294436\n",
       "438214   137389       42265   1.01  1.294124\n",
       "342604   106876        5450   1.01  1.283134\n",
       "424429   133102       24964   1.01  1.275113\n",
       "649670   204080       43961   1.01  1.274052\n",
       "94622     29982         260   1.01  1.272359\n",
       "508168   159326        4920   1.01  1.271624\n",
       "231034    72344       40377   1.01  1.271510\n",
       "58671     18390       34126   1.01  1.271082\n",
       "58670     18390       31717   1.01  1.270711\n",
       "556533   174219        8670   1.01  1.266990\n",
       "379310   118457       34969   1.01  1.265934\n",
       "58676     18390       47626   1.01  1.265028\n",
       "394044   123133       26209   1.01  1.264964\n",
       "75196     23586       25659   1.01  1.264722\n",
       "341262   106464       22935   1.01  1.263821\n",
       "58675     18390       22935   1.01  1.262720\n",
       "82702     25992       34126   1.01  1.262075"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_enc_test\n",
    "test_list=test_labels.values.tolist()\n",
    "test_list\n",
    "preds=[]\n",
    "for i in test_list:\n",
    "    preds.append(sgd_mf_model.predict(int(i[0]), int(i[1])))\n",
    "df_test_pred=test_labels.assign(pred = preds)\n",
    "#df_enc_test_pred['label']=df_enc_test_pred['label']-0.01\n",
    "df_test_pred=df_test_pred.sort_values(by='pred', ascending=False)\n",
    "df_test_pred.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8224848645502936\n",
      "Precision: 0.8248983162709315\n",
      "Recall: 0.8187706998412568\n",
      "F1: 0.8218230861448879\n",
      "ROC-AUC: 0.8224848645502936\n",
      "[[271161  57042]\n",
      " [ 59480 268723]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, roc_auc_score, top_k_accuracy_score\n",
    "metrics=pd.DataFrame()\n",
    "\n",
    "temp=0\n",
    "threshold=0\n",
    "for i in range(0,100):\n",
    "    t=i/100\n",
    "    metrics['label'] = np.where(df_test_pred['label']==1.01, 1, 0)\n",
    "    metrics['pred'] = np.where(df_test_pred['pred']>t, 1, 0)\n",
    "    labels=metrics.label.values\n",
    "    preds_final=metrics.pred.values\n",
    "    x=roc_auc_score(labels, preds_final)\n",
    "    if x>temp:\n",
    "        temp=x\n",
    "        threshold=t\n",
    "#threshold=0.5\n",
    "metrics['label'] = np.where(df_test_pred['label']==1.01, 1, 0)\n",
    "metrics['pred'] = np.where(df_test_pred['pred']>threshold, 1, 0)\n",
    "labels=metrics.label.values\n",
    "preds_final=metrics.pred.values\n",
    "#print(metrics.head(10))\n",
    "#k=50\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(labels, preds_final)}\")\n",
    "print(f\"Precision: {precision_score(labels, preds_final)}\")\n",
    "print(f\"Recall: {recall_score(labels, preds_final)}\")\n",
    "print(f\"F1: {f1_score(labels, preds_final)}\")\n",
    "print(f\"ROC-AUC: {roc_auc_score(labels, preds_final)}\")\n",
    "print(confusion_matrix(labels, preds_final))\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chase\\OneDrive\\CS2316\\anaconda3_2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13faf0b0ec8>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbbUlEQVR4nO3df3RcZ33n8fd3ZjSj0W9Zlh3bsiM7sUlMDCRR87MlZEmok+4mp0D3xIWSZSmhB7Jtgd2e0HJSoN1uC7sbSk+g8XZZdlmaEFIWTI6pTwmBcgqEKAn54TiOFcexFTuWbMv6Lc2M5tk/5o4yV76yRvLI8jP5vM7RmXuf+8zMc3Xlj595nnvnmnMOERHxX2ypGyAiIpWhQBcRqRIKdBGRKqFAFxGpEgp0EZEqkViqN16+fLnr7OxcqrcXEfHSE088ccw51x61bckCvbOzk+7u7qV6exERL5nZK7Nt05CLiEiVUKCLiFQJBbqISJVQoIuIVAkFuohIlZgz0M3sq2bWZ2bPzbLdzOxLZtZjZs+Y2WWVb6aIiMylnB7614Ctp9l+E7Ax+LkD+MqZN0tEROZrzvPQnXP/bGadp6lyK/B/XOF7eH9uZi1mtso5d6RCbZzZHr720wMMjGbKqp+qiXP7NZ00pJbslHsRkbOiEim3BjhUst4blJ0S6GZ2B4VePOvWrVvQmx04PsZnv/d88Hqnr1v8qvf1y+u5ecuqBb2fiIgvKhHoUbEaedcM59x2YDtAV1fXgu6sMZUvPO1L2y7llreuPm3dwyfHueYvf8jQeHYhbyUi4pVKnOXSC6wtWe8ADlfgdWdR/v8DjbWF/6+GJ3KL1RgRkXNGJQJ9B/CB4GyXq4DBxRo/n6/6ZAIzGJ5QD11Eql85py3eD/wMeJOZ9ZrZh8zs98zs94IqO4H9QA/wP4CPLlprS9tVRp1YzHAOHt3bv+jtERFZauWc5bJtju0O+FjFWjSHhdzT+tlXByvfEBGRc0zVXyn6wWs7AcjnFzQHKyLiDe9Ozi7G8lynLBataUkDhYnRpnQCK/eJIm8g2ak8Y5kpxjNTjGenGMvkyE45Ll7ViHMwkZ1iIpsnnYzTnK4JPW88O1XYnskzkSssj2emmMjlmchO0d6Yor0hNf0ak7nC40R2ismgzkRuisls4fmrm9M0pRNMZvPT2ydzeXJ5x4bl9Vy0qpFkPMZkrrC9ta6Glrok+bwLygr1J7N5MlPF9wyXF5en8o4LVzSweVUTuSn3ep2gfiaXp6O1jmQiNr2eyeVpa0jRVJsgM1WoWywPL0+RnXKsXZYmHjPaG1Ik4jGcczhXGBKuNO8Cfb6agj++T3/3Ob739GHu//BVXH1B2xK3Ss4W5xwjkzkmsnnaG1OhbRPZKYbGs7TUJUkmzv6H1Uwuz8hkjpGJXOFxMsfIZJbhYH10MsfoZCFcRzNTjE3mGMtMMZaZYjSTY2yy8NicrmFDewNrWtK0NxaCcyxTqFtYnpplOTcd4rl5fIJtq08GIZyfPo14qdXEjezUudGW2SRiRixmZHJ5/uI3t/DbVy7sWpzTvkfFX/EssbKmRaGpthDo33u6cCblC68NcfUFbRw4Nsrf/LCHGzevYOsluujoXJLPOwbHsxwfzXBiNMOJ0cnC8kiG46MZcvk8V65vIxEzBsayDIxlGBzPMjCaYWAsy8mxDCfHg8ex7HRYrWlJk07GGRzPMjieJZPLA3BBez23X9PJ4Fh2etvgeBYzeNvaVqbyeYYmcgxPZBkazzE0kWVoPMvQRI6h8SyjmRxvOq+JptoEdck4l6xuZjQzxchkdjqsh0tDeyLH8GRu+v3nkq6JU5+KU5csvH5dMk5DKsGKxhSJWIw9R4b42UvHODby+tXTMYO6ZIJ0UD9dE59ebq2rIZ1MUBeUpZPx8HIyTromwdB4lkMDY9TWFJ6fTMTo6RshO5UnXROntiZObU0seIxP16utiZGuiZOqiWMGPX0jGJTUi5FKvP7cVCJ4jUQci8G+o8PEY7Hp8lSisDw6OcXeo8O8cnyUmnihLBGPsb9/BAdBvXj4eTWvlxXWw8ujkzl+eegkx0cyJIvliViwHCfvHAdPjFETj01vj5vxyvFRMAvVT8YL75eMx6frTubyHBkcZyrv6B0YJxE3UvEYb17dVOl/NoCHgT7fSdFL17VwxfplfPCaTj7690/SPzzJF3/wIl/+0UtkcnmOjUwq0M9APu84NjpJ39AkG1c2kErEgcKpoq8NTnBkcIL+4Umue1M7jbUJ+ocn6Rsu1O8fnqBvePL1suEJ+oYK4T1bz68hlWBkMsf//fnBUHltTYyWdJKWuhpa65JsXNFAS10y+DheQ0/fCL0D4zSna6Z/mtI1xGPGPf/0Ind/dzdQCM/mdA2NtQn29Y2wa/fR6ddvrK2hqTZBU7rwEX/tsjqa0jUMjGbY1zdCJpfnxaPD7Np9lGQiRmMqQUNtgoZUgvpUgvOaaqfXG2oThe2pBA21NTSk4jSkaqa3N9YWwztBvMyP5sdGJknEjHQyTjIeO2eGFy9b1zqv+pefvyyyvK0B1rXVVaJJIZtWNlb8NZeKd4E+XyubannwI1cD0JKuYfs/7yeXd9zy1tXsfW2YQwNjfOTr3ew+PMQPPnEdtTXxyNfZfXiQ+39xkM62en731zbgnGNf3wjnt9VNh9i5YjI3xfBEjuUNqbkrz8E5x7GRDL0DYxwaGC88nig89g6M8+rAOJmpQk8zXROnozXNkcEJRibLu5grZtDWUBhjXdGUYvOqJtobUyyrT9FWn2RZ8NPWUHhMJeK8enKcV46P0lr3eoDPdtzKse2KdWRyeZrTNaGhl+KQRGNtouxjPJGdwowl+ZuoxPEWv3kX6C6YFl1I52NVc5pMbpT/9u4t3Pq2NfzHbz3NQ0/0sr9/FIDuAwMcGRznPZd1BOewO378Yj/3PtrD4wcGAFhWn8Q5uP/xg+zvH+WPb76IO95+Qeh9xjI5Uol42T2rck3lHS8eHSY7lectHS0ADE1kee7VweBniBdeG2Jf3wjOwUeu28BdWy86paeWm8pz4Pgoh09OcO2Fy4nHjMGxLC8dG2F//yj7+wuPLx8b5eCJMcazU6Hnt9Un6WhNs3l1E+9680rWtKR57OUTvDowzqrmWq69cDmrmms5r7mWVc1pXjw6zItHh6dDe0VjLe2NKVY0plhWnyQRn9/49ZqW9PRkdyWUTvKVKgxxzO+fyJn8xyJyprwL9DPxt++/nJqEsaq5EAbvvmwNqUSMX+lcxh9+85f8zlcfw7nCl3mNZ6f4wq69PNM7yOrmWj79GxczNJ7lSz/s4T/v3MPl57cCozz5ykkAxjNT7Hz2CN/55av89KXjfOz6C/nEjZum39s5x3OvDvHsq4O89/KOyEm4k2MZGlKJ6YAbnczxiwMn6D5wgqcOnuTpQycZzRTC9aoNy3htcIIDx8emn7+mJc3Fqxr5lc5lfOOxg9z34/3c9+P91CfjfPT6C9l3dJi9R0d4qW9kuledSsRoSCU4XvLtlYmYsa6tjg3LG/jVjctZ25pm7bI6Olrr6GhNUx/xzZUfuLpz1t/7FeujP0KLSGV5G+gL6fvOHH+75oLlXHPBco6PTFKXjHPReY08efAkf/TQM+w/NkpHa5r/8u4tvOeyQgCfGM1Qm4xzw8Ur2bSykY9940meeGWAz+zYzT882cvwRI6O1jTtDSl+sq+fj9+wkd2Hh/h/T73K9589wuHBCQDqU3FufdsapvKOJ14Z4JE9R/nxi/288Now/+atq+lsq+OnLx3n6UMnyeUd8Zhx8apG3nN5B231Ke75wYscOjHOljXN/FbXWi5Z08yWNc0sq09O79vHb9zEH3/72WASaYwv7NrL6uZaNp3XyNs3LWfTika++fghHI4NyxvY0F7PhvYGLmivZ+2yOmrm2WsWkaVnbiGXXlZAV1eX6+7unvfz9hwZ4qa//glfed9l3FTBr8TNTRXOc93ymV3EY8ad11/I7/7ahtN+hP7yj3r4/D/uJRmPsfWS8/jtK9dx5fpl/OX3X+Cr//Iy57fV09M3QjIe4+2b2nnXm1fy5w8/z5aOZjpa6vjBnqMcH81QEzcuP7+Vk2NZXnhtmJjBWzpauOaCNq6+oI3Lz28NffTP513Z57AWx/rPa66dPuNHRPxlZk8457qitnnbQ6+0RDxGIg7f/MjVnNdUy+oyxmjfd+X5rGys5fqLVoR6x9e9qZ3tP9nPsvokf/GbW7h5y3m01BW2P/pCH99/7jUaUoNcf9EKfv3NK7luUzuNtTX0DU2w57VhLl3Xctrwnc8FCWZWVbP4IjI7bwN9sc7Ims8pVs3pGt5zeccp5ddcsJy9f3ZT5Dj5Z295M79z1flc3tl6ypkQK5pqWdFUO/9Gi4jgYaAv0QjRvM125aFCW0QWi8czX+fGRRMiIucK7wLdzeOORSIibyTeBbqIiETzNtDPka+pEBE5Z3gX6L5MioqInG3eBXqROugiImHeBrqIiIQp0EVEqoS3gX6ufHm/iMi5wrtA16SoiEg07wK9SP1zEZEw7wJdV4qKiETzLtBFRCSat4GuOVERkTDvAl2ToiIi0bwL9CL10EVEwrwLdHXQRUSieRfoIiISraxAN7OtZrbXzHrM7K6I7evM7FEze8rMnjGzmyvf1BnvqTPRRURC5gx0M4sD9wI3AZuBbWa2eUa1TwMPOucuBW4DvlzphhY5zYqKiEQqp4d+BdDjnNvvnMsADwC3zqjjgKZguRk4XLkmiohIOcoJ9DXAoZL13qCs1GeA95tZL7AT+A9RL2Rmd5hZt5l19/f3L6C5JZOiGnEREQkpJ9CjonPmuMc24GvOuQ7gZuDrZnbKazvntjvnupxzXe3t7fNvrYiIzKqcQO8F1pasd3DqkMqHgAcBnHM/A2qB5ZVo4GzUQRcRCSsn0B8HNprZejNLUpj03DGjzkHgnQBmdjGFQF/YmMocNCcqIhJtzkB3zuWAO4FdwB4KZ7PsNrPPmdktQbVPAh82s6eB+4F/53Q6iojIWZUop5JzbieFyc7SsrtLlp8Hrq1s005PdywSEQnz8EpRdfxFRKJ4GOgF6p+LiIR5F+gamRcRieZdoIuISDRvA11zoiIiYd4FukZcRESieRfoRfr6XBGRMO8CXZOiIiLRvAt0ERGJ5m2ga1JURCTMu0DXV8SIiETzLtCL1EEXEQnzLtDVPxcRieZdoIuISDR/A11jLiIiId4FuuZERUSieRfoRbpSVEQkzLtAd5oWFRGJ5F2gi4hING8DXVeKioiE+RfoGnEREYnkX6AH1EEXEQnzLtDVQRcRieZdoIuISDRvA900KyoiEuJdoOtKURGRaN4FepE66CIiYd4GuoiIhHkX6Lr0X0QkmneBXqQRFxGRsLIC3cy2mtleM+sxs7tmqfNvzex5M9ttZn9f2Wa+TpOiIiLREnNVMLM4cC9wI9ALPG5mO5xzz5fU2Qh8CrjWOTdgZisWq8EiIhKtnB76FUCPc26/cy4DPADcOqPOh4F7nXMDAM65vso281Q6y0VEJKycQF8DHCpZ7w3KSm0CNpnZv5jZz81sa9QLmdkdZtZtZt39/f0LarBGXEREopUT6FF94Zm5mgA2Au8AtgF/Z2YtpzzJue3OuS7nXFd7e/t821pGs0RE3rjKCfReYG3JegdwOKLOd51zWefcy8BeCgFfcU6zoiIikcoJ9MeBjWa23sySwG3Ajhl1vgNcD2BmyykMweyvZENFROT05gx051wOuBPYBewBHnTO7Tazz5nZLUG1XcBxM3seeBT4T86544vVaNCkqIjITHOetgjgnNsJ7JxRdnfJsgM+EfwsKg24iIhE05WiIiJVwr9AVxddRCSSf4EuIiKRvA103bFIRCTMu0DX1+eKiETzLtCL1D8XEQnzLtB1oaiISDTvAl1ERKJ5G+iaExURCfMu0DXkIiISzbtALzJNi4qIhHgX6Oqgi4hE8y7QRUQkmreBrklREZEw7wJddywSEYnmXaCLiEg07wJd/XMRkWjeBbqIiETzNtA1KSoiEuZdoGtOVEQkmneBXqQrRUVEwrwNdBERCfMw0DXmIiISxcNAL9CkqIhImHeBrklREZFo3gV6kXroIiJh3ga6iIiEeRfoGnEREYnmXaAX6Tx0EZEw7wJdk6IiItG8C3QREYlWVqCb2VYz22tmPWZ212nqvdfMnJl1Va6Js73XYr+DiIhf5gx0M4sD9wI3AZuBbWa2OaJeI/D7wGOVbmQpp2lREZFI5fTQrwB6nHP7nXMZ4AHg1oh6fwZ8HpioYPtmpQ66iEhYOYG+BjhUst4blE0zs0uBtc65h0/3QmZ2h5l1m1l3f3//vBsLmhQVEZlNOYEe1RmejlUziwH3AJ+c64Wcc9udc13Oua729vbyWykiInMqJ9B7gbUl6x3A4ZL1RuAS4EdmdgC4Ctix2BOjmhQVEQkrJ9AfBzaa2XozSwK3ATuKG51zg8655c65TudcJ/Bz4BbnXPdiNFgjLiIi0eYMdOdcDrgT2AXsAR50zu02s8+Z2S2L3cDZqYsuIlIqUU4l59xOYOeMsrtnqfuOM2/WaduymC8vIuItXSkqIlIlvA10TYqKiIR5G+giIhLmbaCrgy4iEuZdoGtOVEQkmneBLiIi0bwNdNOsqIhIiHeBrq/PFRGJ5l2gF6l/LiIS5m2gi4hImHeBrrNcRESieRfoRZoTFREJ8y7Q1UMXEYnmXaAXmaZFRURCvA10EREJ8y7QNeIiIhLNu0Av0qSoiEiYd4GuOxaJiETzLtBFRCSaAl1EpEp4F+gacBERieZdoBdpUlREJMy/QFcXXUQkkn+BHtANLkREwrwNdBERCfMu0HXHIhGRaN4FepEGXEREwrwLdF0oKiISzbtAFxGRaN4Guk5yEREJKyvQzWyrme01sx4zuyti+yfM7Hkze8bMHjGz8yvf1AKNuIiIRJsz0M0sDtwL3ARsBraZ2eYZ1Z4CupxzbwEeAj5f6Yae0i5Ni4qIhJTTQ78C6HHO7XfOZYAHgFtLKzjnHnXOjQWrPwc6KtvM0vdarFcWEfFbOYG+BjhUst4blM3mQ8D3ozaY2R1m1m1m3f39/eW3UkRE5lROoEeNbUT2k83s/UAX8IWo7c657c65LudcV3t7e/mtjHyvM3q6iEjVSZRRpxdYW7LeARyeWcnMbgD+BLjOOTdZmeadSleKiohEK6eH/jiw0czWm1kSuA3YUVrBzC4F7gNucc71Vb6Zp1IHXUQkbM5Ad87lgDuBXcAe4EHn3G4z+5yZ3RJU+wLQAHzLzH5pZjtmeTkREVkk5Qy54JzbCeycUXZ3yfINFW7Xadpytt5JRMQv3l4pqjEXEZEw7wJdHXQRkWjeBXqRrhQVEQnzNtBFRCTMv0DXrKiISCT/Aj2gK0VFRMK8C3T1z0VEonkX6EXqoIuIhHkb6CIiEuZdoGtOVEQkmneBXmSaFRURCfEu0J266CIikbwL9CL1z0VEwrwNdBERCfMu0DXgIiISzbtAL9KcqIhImHeBrjlREZFo3gV6kb4+V0QkzNtAFxGRMO8CXSMuIiLRvAv0aRpxEREJ8S7QdaWoiEg07wK9SKctioiEeRvoIiISpkAXEakS3ga6RlxERMK8DXQREQnzLtB1kouISDTvAr1IdywSEQnzLtCdrhUVEYnkXaAXqX8uIhJWVqCb2VYz22tmPWZ2V8T2lJl9M9j+mJl1VrqhIiJyenMGupnFgXuBm4DNwDYz2zyj2oeAAefchcA9wF9VuqFFmhQVEYlWTg/9CqDHObffOZcBHgBunVHnVuB/B8sPAe+0RZ611JyoiEhYOYG+BjhUst4blEXWcc7lgEGgbeYLmdkdZtZtZt39/f0LavCG9gZ+Y8sqYkp0EZGQRBl1opJz5sBHOXVwzm0HtgN0dXUtaPDkxs0ruXHzyoU8VUSkqpXTQ+8F1pasdwCHZ6tjZgmgGThRiQaKiEh5ygn0x4GNZrbezJLAbcCOGXV2ALcHy+8Ffuj0xeUiImfVnEMuzrmcmd0J7ALiwFedc7vN7HNAt3NuB/A/ga+bWQ+Fnvlti9loERE5VTlj6DjndgI7Z5TdXbI8AfxWZZsmIiLz4e2VoiIiEqZAFxGpEgp0EZEqoUAXEakStlRnF5pZP/DKAp++HDhWweb4QPv8xqB9fmM4k30+3znXHrVhyQL9TJhZt3Oua6nbcTZpn98YtM9vDIu1zxpyERGpEgp0EZEq4Wugb1/qBiwB7fMbg/b5jWFR9tnLMXQRETmVrz10ERGZQYEuIlIlvAv0uW5Y7SszW2tmj5rZHjPbbWZ/EJQvM7N/MrN9wWNrUG5m9qXg9/CMmV22tHuwMGYWN7OnzOzhYH19cKPxfcGNx5NBeVXciNzMWszsITN7ITjWV78BjvHHg7/p58zsfjOrrcbjbGZfNbM+M3uupGzex9bMbg/q7zOz26PeazZeBXqZN6z2VQ74pHPuYuAq4GPBvt0FPOKc2wg8EqxD4XewMfi5A/jK2W9yRfwBsKdk/a+Ae4L9HaBwA3I4izciX2R/Dfyjc+4i4K0U9r1qj7GZrQF+H+hyzl1C4Su4b6M6j/PXgK0zyuZ1bM1sGfCnwJUU7uf8p8X/BMrinPPmB7ga2FWy/ingU0vdrkXa1+8CNwJ7gVVB2Spgb7B8H7CtpP50PV9+KNz96hHgXwEPU7iV4TEgMfN4U/g+/quD5URQz5Z6H+a5v03AyzPbXeXHuHi/4WXBcXsY+PVqPc5AJ/DcQo8tsA24r6Q8VG+uH6966JR3w2rvBR8zLwUeA1Y6544ABI8rgmrV8Lv4IvBHQD5YbwNOusKNxiG8T2XdiPwctwHoB/5XMMz0d2ZWTxUfY+fcq8B/BQ4CRygctyeo7uNcar7H9oyOuW+BXtbNqH1mZg3APwB/6JwbOl3ViDJvfhdm9q+BPufcE6XFEVVdGdt8kQAuA77inLsUGOX1j+BRvN/nYLjgVmA9sBqopzDcMFM1HedyzLafZ7T/vgV6OTes9paZ1VAI8284574dFB81s1XB9lVAX1Du++/iWuAWMzsAPEBh2OWLQEtwo3EI71M13Ii8F+h1zj0WrD9EIeCr9RgD3AC87Jzrd85lgW8D11Ddx7nUfI/tGR1z3wK9nBtWe8nMjMK9Wfc45/57yabSG3DfTmFsvVj+gWC2/CpgsPjRzgfOuU855zqcc50UjuMPnXPvAx6lcKNxOHV/vb4RuXPuNeCQmb0pKHon8DxVeowDB4GrzKwu+Bsv7nPVHucZ5ntsdwHvMrPW4NPNu4Ky8iz1JMICJh1uBl4EXgL+ZKnbU8H9+lUKH62eAX4Z/NxMYfzwEWBf8LgsqG8Uzvh5CXiWwlkES74fC9z3dwAPB8sbgF8APcC3gFRQXhus9wTbNyx1uxe4r28DuoPj/B2gtdqPMfBZ4AXgOeDrQKoajzNwP4V5giyFnvaHFnJsgX8f7H8P8MH5tEGX/ouIVAnfhlxERGQWCnQRkSqhQBcRqRIKdBGRKqFAFxGpEgp0EZEqoUAXEakS/x+9fwJQYp+trgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "precisions=[]\n",
    "#recalls=[]\n",
    "for k in range(1000):\n",
    "    precisions.append(precision_score(labels[:k], preds_final[:k]))\n",
    "    #recalls.append(recall_score(labels[:k], preds_final[:k]))\n",
    "plt.plot(precisions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
